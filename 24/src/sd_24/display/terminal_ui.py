"""çµ±åˆã‚¿ãƒ¼ãƒŸãƒŠãƒ«UIåˆ¶å¾¡"""

import asyncio
import os
from typing import Dict, Any, Optional, Set

from .message_formatter import MessageFormatter
from .task_display import TaskDisplayEngine, TaskMonitor


class TerminalUI:
    """çµ±åˆã‚¿ãƒ¼ãƒŸãƒŠãƒ«UIåˆ¶å¾¡ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.formatter = MessageFormatter()
        self.task_display = TaskDisplayEngine()
        self.task_monitor = TaskMonitor(self.task_display)
        self.seen_messages: Set = set()
        self.is_debug_mode = False

        # è¡¨ç¤ºè¨­å®š
        self.show_task_progress = False  # ä¸€æ™‚çš„ã«ç„¡åŠ¹åŒ–
        self.show_subgraph_details = True
        self.auto_clear_screen = False

    def clear_screen(self):
        """ç”»é¢ã‚¯ãƒªã‚¢"""
        if self.auto_clear_screen:
            os.system('cls' if os.name == 'nt' else 'clear')

    def print_startup_banner(self, debug_mode: bool = False):
        """èµ·å‹•æ™‚ã®ãƒãƒŠãƒ¼è¡¨ç¤º"""
        self.is_debug_mode = debug_mode

        print(self.formatter.format_section_header("æ–‡ç« åŸ·ç­†æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ  å‹•ä½œç¢ºèª"))

        if debug_mode:
            print(self.formatter.format_info_message("\nğŸ› ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­..."))
            print(self.formatter.format_info_message(
                "(é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã™ã‚‹ã«ã¯ã€--debugã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å¤–ã—ã¦ãã ã•ã„)"))
        else:
            print(self.formatter.format_info_message("\nğŸ“‹ é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­..."))
            print(self.formatter.format_info_message(
                "(è©³ç´°ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¦‹ã‚‹ã«ã¯ã€--debugã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä»˜ã‘ã¦ãã ã•ã„)"))
            print(self.formatter.format_info_message(
                "ä¾‹: uv run python main.py --debug"))

        print(self.formatter.format_info_message(
            "\nâœï¸ Writerå®Ÿè£…: create_react_agentç‰ˆï¼ˆå°ã•ãªãƒ„ãƒ¼ãƒ«ã®çµ„ã¿åˆã‚ã›ï¼‰"))

    def print_test_header(self, test_name: str, input_text: str):
        """ãƒ†ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º"""
        print(self.formatter.format_section_header(f"ãƒ†ã‚¹ãƒˆ: {test_name}"))
        print(f"å…¥åŠ›: {input_text}\n")

    def print_node_output(self, node_name: str, node_output: Dict[str, Any], namespace: str = ""):
        """ãƒãƒ¼ãƒ‰å‡ºåŠ›ã‚’è¡¨ç¤º"""
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
        print(self.formatter.format_node_header(node_name, namespace))

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†
        if "messages" in node_output:
            for msg in node_output["messages"]:
                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
                msg_id = getattr(msg, "id", None) or str(
                    hash(str(msg.content)))
                if msg_id not in self.seen_messages:
                    self.seen_messages.add(msg_id)
                    formatted_message = self.formatter.format_message(msg)
                    if formatted_message:  # ç©ºæ–‡å­—åˆ—ã§ãªã„å ´åˆã®ã¿è¡¨ç¤º
                        print(formatted_message)

        # ãã®ä»–ã®çŠ¶æ…‹æƒ…å ±
        for key, value in node_output.items():
            if key != "messages":
                print(f"  {key}: {value}")

    async def run_with_task_monitoring(
        self,
        app: Any,
        input_data: Dict[str, Any],
        config: Optional[Dict] = None,
        test_name: str = "",
        input_text: str = ""
    ):
        """ã‚¿ã‚¹ã‚¯ç›£è¦–ä»˜ãã§å®Ÿè¡Œ"""
        self.print_test_header(test_name, input_text)

        # ã‚¿ã‚¹ã‚¯ç›£è¦–ã‚’é–‹å§‹
        if self.show_task_progress:
            monitoring_task = asyncio.create_task(
                self.task_monitor.start_monitoring(self._on_task_update)
            )

        try:
            # ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
            execution_task = asyncio.create_task(
                self._run_main_execution(app, input_data, config)
            )

            # å®Ÿè¡Œå®Œäº†ã¾ã§å¾…æ©Ÿ
            await execution_task

        finally:
            # ã‚¿ã‚¹ã‚¯ç›£è¦–ã‚’åœæ­¢
            if self.show_task_progress:
                self.task_monitor.stop_monitoring()
                try:
                    await asyncio.wait_for(monitoring_task, timeout=1.0)
                except asyncio.TimeoutError:
                    monitoring_task.cancel()

        # æœ€çµ‚ã‚¿ã‚¹ã‚¯çŠ¶æ³è¡¨ç¤º
        if self.show_task_progress:
            final_status = self.task_display.render_current_status()
            print(final_status)

        print(self.formatter.format_completion_message("ãƒ†ã‚¹ãƒˆå®Œäº†"))

    async def _run_main_execution(self, app: Any, input_data: Dict[str, Any], config: Optional[Dict]):
        """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œå‡¦ç†"""
        stream_config = {
            "stream_mode": "updates",
            "subgraphs": True
        }

        if config:
            async for chunk in app.astream(input_data, config, **stream_config):
                self._process_chunk(chunk)
        else:
            async for chunk in app.astream(input_data, **stream_config):
                self._process_chunk(chunk)

    def _process_chunk(self, chunk: Any):
        """ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†"""
        if isinstance(chunk, tuple):
            # ã‚µãƒ–ã‚°ãƒ©ãƒ•ã®å‡ºåŠ›
            namespace, output = chunk
            if self.show_subgraph_details:
                namespace_display = f"ã‚µãƒ–ã‚°ãƒ©ãƒ•: {namespace}" if namespace else ""
                for node_name, node_output in output.items():
                    self.print_node_output(
                        node_name, node_output, namespace_display)
        else:
            # ãƒ¡ã‚¤ãƒ³ã‚°ãƒ©ãƒ•ã®å‡ºåŠ›
            for node_name, node_output in chunk.items():
                self.print_node_output(node_name, node_output)

    async def _on_task_update(self, status_display: str):
        """ã‚¿ã‚¹ã‚¯æ›´æ–°æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        # ç¾åœ¨ã®è¡¨ç¤ºé ˜åŸŸã‚’ä¸€æ™‚çš„ã«ã‚¯ãƒªã‚¢ã—ã¦ã€ã‚¿ã‚¹ã‚¯çŠ¶æ³ã‚’ä¸Šéƒ¨ã«è¡¨ç¤º
        # ã“ã®å®Ÿè£…ã§ã¯ã€ã‚¿ã‚¹ã‚¯çŠ¶æ³ãŒæ›´æ–°ã•ã‚ŒãŸæ™‚ã«ã®ã¿è¡¨ç¤º
        pass  # ç¾åœ¨ã¯ä½•ã‚‚ã—ãªã„ï¼ˆå°†æ¥çš„ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã‚’å®Ÿè£…ï¼‰

    async def run_debug_mode(
        self,
        app: Any,
        input_data: Dict[str, Any],
        config: Optional[Dict] = None,
        test_name: str = "",
        input_text: str = ""
    ):
        """ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ"""
        self.print_test_header(f"ğŸ› ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: {test_name}", input_text)

        print(self.formatter.format_info_message("ğŸ“Š ã‚¤ãƒ™ãƒ³ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹...\n"))

        event_config = config or {}

        try:
            async for event in app.astream_events(input_data, version="v2", config=event_config):
                self._process_debug_event(event)
        except Exception as e:
            print(self.formatter.format_error_message(f"ãƒ‡ãƒãƒƒã‚°å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"))
            raise

        print(self.formatter.format_completion_message("ãƒ‡ãƒãƒƒã‚°å®Œäº†"))

    def _process_debug_event(self, event: Dict[str, Any]):
        """ãƒ‡ãƒãƒƒã‚°ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†"""
        event_type = event.get("event", "")

        if event_type == "on_chain_start":
            chain_name = event.get("name", "")
            print(f"ğŸ”— ãƒã‚§ãƒ¼ãƒ³é–‹å§‹: {chain_name}")

        elif event_type == "on_chain_end":
            chain_name = event.get("name", "")
            print(f"âœ”ï¸ ãƒã‚§ãƒ¼ãƒ³çµ‚äº†: {chain_name}")

        elif event_type == "on_tool_start":
            tool_name = event.get("name", "")
            print(f"ğŸ”§ ãƒ„ãƒ¼ãƒ«é–‹å§‹: {tool_name}")

        elif event_type == "on_tool_end":
            tool_name = event.get("name", "")
            print(f"âœ”ï¸ ãƒ„ãƒ¼ãƒ«çµ‚äº†: {tool_name}")

        elif event_type == "on_chat_model_stream":
            data = event.get("data", {})
            chunk = data.get("chunk", None)
            if chunk:
                content = ""
                if hasattr(chunk, "content"):
                    content = chunk.content
                elif isinstance(chunk, dict):
                    content = chunk.get("content", "")

                if content:
                    truncated_content = self.formatter.truncate_text(
                        str(content), 100)
                    print(f"ğŸ’¬ LLMå‡ºåŠ›: {truncated_content}")

        elif event_type == "on_chat_model_start":
            model_name = event.get("name", "")
            print(f"ğŸ¤– ãƒ¢ãƒ‡ãƒ«é–‹å§‹: {model_name}")

    def print_completion_summary(self):
        """å®Œäº†æ™‚ã®ã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print(self.formatter.format_section_header("ğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼"))

    def print_error_summary(self, error: Exception):
        """ã‚¨ãƒ©ãƒ¼æ™‚ã®ã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print(self.formatter.format_error_message(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error}"))
        print("\nä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
        print("1. ANTHROPIC_API_KEYãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹")
        print("2. TAVILY_API_KEYãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹")
        print("3. å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ (uv sync)")

    def configure(
        self,
        show_task_progress: bool = True,
        show_subgraph_details: bool = True,
        auto_clear_screen: bool = False
    ):
        """è¡¨ç¤ºè¨­å®š"""
        self.show_task_progress = show_task_progress
        self.show_subgraph_details = show_subgraph_details
        self.auto_clear_screen = auto_clear_screen
