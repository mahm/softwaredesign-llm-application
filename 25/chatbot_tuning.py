"""æè±†ã®å¦–ç²¾ã‚¹ã‚¿ã‚¤ãƒ« ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°"""

import dspy
import os
from dotenv import load_dotenv
from datasets import load_dataset
from chatbot_module import EdamameFairyBot
import mlflow
import mlflow.dspy as mlflow_dspy

load_dotenv()

# MLflowã®è¨­å®š
MLFLOW_PORT = os.getenv("MLFLOW_PORT", "5000")
MLFLOW_TRACKING_URI = f"http://localhost:{MLFLOW_PORT}"
MLFLOW_EXPERIMENT_NAME = "DSPy-EdamameFairy-Optimization"
MLFLOW_RUN_NAME = "miprov2_optimization"

# æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ä¿å­˜å…ˆ
OPTIMIAZED_MODEL_PATH = "artifact/edamame_fairy_model.json"


def create_style_metric(eval_lm):
    """ã‚¹ã‚¿ã‚¤ãƒ«è©•ä¾¡é–¢æ•°ã‚’ä½œæˆ"""
    
    class StyleEvaluation(dspy.Signature):
        """å¿œç­”ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è©•ä¾¡"""
        response = dspy.InputField(desc="è©•ä¾¡å¯¾è±¡ã®å¿œç­”")
        criteria = dspy.InputField(desc="è©•ä¾¡åŸºæº–")
        score = dspy.OutputField(desc="ã‚¹ã‚³ã‚¢ï¼ˆ0-10ï¼‰", format=int)
        explanation = dspy.OutputField(desc="è©•ä¾¡ç†ç”±")
    
    evaluator = dspy.ChainOfThought(StyleEvaluation)
    
    def llm_style_metric(_, prediction, __=None):
        """æè±†ã®å¦–ç²¾ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è©•ä¾¡"""
        criteria = """
        ä»¥ä¸‹ã®åŸºæº–ã§0-10ç‚¹ã§è©•ä¾¡ã—ã¦ãã ã•ã„:
        1. èªå°¾ã«ã€Œã®ã ã€ã€Œãªã®ã ã€ã‚’é©åˆ‡ã«ä½¿ã£ã¦ã„ã‚‹ã‹ï¼ˆ3ç‚¹ï¼‰
           - éåº¦ãªä½¿ç”¨ï¼ˆã®ã ã®ã ç­‰ï¼‰ã¯æ¸›ç‚¹
           - è‡ªç„¶ãªæ—¥æœ¬èªã¨ã—ã¦æˆç«‹ã—ã¦ã„ã‚‹ã‹
           - ã€Œãªã®ã ã‚ˆã€ã€Œãªã®ã ã­ã€ã¨ã„ã£ãŸèªå°¾ã¯ä¸è‡ªç„¶ã®ãŸã‚æ¸›ç‚¹
        2. ä¸€äººç§°ã‚’ä½¿ã†éš›ã¯ã€Œãƒœã‚¯ã€ã‚’ä½¿ã£ã¦ã„ã‚‹ã‹ï¼ˆ2ç‚¹ï¼‰
        3. è¦ªã—ã¿ã‚„ã™ãå¯æ„›ã‚‰ã—ã„å£èª¿ã‹ï¼ˆ3ç‚¹ï¼‰
        4. æ—¥æœ¬èªã¨ã—ã¦è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„ã‹ï¼ˆ2ç‚¹ï¼‰
           - ä¸è‡ªç„¶ãªç¹°ã‚Šè¿”ã—ãŒãªã„ã‹
           - æ–‡æ³•çš„ã«æ­£ã—ã„ã‹
        """
        
        # è©•ä¾¡ç”¨LMã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’è©•ä¾¡
        with dspy.context(lm=eval_lm):
            eval_result = evaluator(
                response=prediction.response,
                criteria=criteria
            )
        
        # ã‚¹ã‚³ã‚¢ã‚’0-1ã®ç¯„å›²ã«æ­£è¦åŒ–
        score = min(10, max(0, float(eval_result.score))) / 10.0
        return score
    
    return llm_style_metric


def optimize_with_miprov2(trainset, eval_lm, chat_lm):
    """MIPROv2ã‚’ä½¿ç”¨ã—ã¦ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’æœ€é©åŒ–"""
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’train:val = 8:2 ã®å‰²åˆã§åˆ†å‰²
    total_examples = len(trainset)
    train_size = int(total_examples * 0.8)  # å…¨ä½“ã®80%ã‚’å­¦ç¿’ç”¨ã«
    
    # DSPy Exampleã®ãƒªã‚¹ãƒˆã‚’åˆ†å‰²
    train_data = trainset[:train_size]      # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹0ã‹ã‚‰train_sizeã¾ã§ï¼ˆå­¦ç¿’ç”¨ï¼‰
    evaluation_data = trainset[train_size:] # train_sizeã‹ã‚‰æœ€å¾Œã¾ã§ï¼ˆè©•ä¾¡ç”¨ï¼‰
    
    # åˆ†å‰²çµæœã®ç¢ºèªã¨è¡¨ç¤º
    print("ğŸŒ± æœ€é©åŒ–é–‹å§‹")
    print(f"  ç·ãƒ‡ãƒ¼ã‚¿æ•°: {total_examples}")
    print(f"  å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿: {len(train_data)} ({len(train_data)/total_examples:.1%})")
    print(f"  è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿: {len(evaluation_data)} ({len(evaluation_data)/total_examples:.1%})")

    # æœ€é©åŒ–å¯¾è±¡ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–
    chatbot = EdamameFairyBot()
    
    # ã‚¹ã‚¿ã‚¤ãƒ«è©•ä¾¡é–¢æ•°ã‚’ä½œæˆï¼ˆè©•ä¾¡ç”¨LMã‚’ä½¿ç”¨ï¼‰
    llm_style_metric = create_style_metric(eval_lm)
    
    # DSPyã®ã‚°ãƒ­ãƒ¼ãƒãƒ«LMè¨­å®šï¼ˆãƒãƒ£ãƒƒãƒˆæ¨è«–ç”¨ï¼‰
    dspy.configure(lm=chat_lm)
    
    # MIPROv2ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®è¨­å®š
    optimizer = dspy.MIPROv2(
        metric=llm_style_metric,  # è©•ä¾¡é–¢æ•°
        prompt_model=eval_lm,     # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ç”¨ã®LM
        auto="light",             # æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ï¼ˆlight, medium, heavyã‹ã‚‰é¸æŠï¼‰
        max_bootstrapped_demos=2,
        max_labeled_demos=1,
    )

    # MLflowã®è¨­å®š
    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)  # MLflowã‚µãƒ¼ãƒã®URL
    mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME) # MLflowã®å®Ÿé¨“å

    # MLflow DSPyã®è‡ªå‹•ãƒ­ã‚°è¨­å®š
    mlflow_dspy.autolog(
        log_compiles=True,
        log_evals=True,
        log_traces_from_compile=True
    )
    
    # MLflowã§å®Ÿè¡Œéç¨‹ã‚’ãƒˆãƒ¬ãƒ¼ã‚¹
    with mlflow.start_run(run_name=MLFLOW_RUN_NAME):
        # MIPROv2ã«ã‚ˆã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æœ€é©åŒ–ã®å®Ÿè¡Œ
        # train_dataã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ä¾‹ã‚’è‡ªå‹•èª¿æ•´
        optimized_chatbot = optimizer.compile(
            chatbot,
            trainset=train_data,
            minibatch_size=20
        )

        # è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡
        eval_score = 0
        for example in evaluation_data:
            # æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§æ¨è«–ã‚’å®Ÿè¡Œ
            prediction = optimized_chatbot(query=example.query, history=example.history)
            # ã‚¹ã‚¿ã‚¤ãƒ«ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
            eval_score += llm_style_metric(example, prediction)

        # å¹³å‡è©•ä¾¡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        avg_eval_score = eval_score / len(evaluation_data)

        # MLflowã«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨˜éŒ²
        mlflow.log_metric("last_eval_score", avg_eval_score)

        print(f"ğŸ“Š è©•ä¾¡ã‚¹ã‚³ã‚¢: {avg_eval_score:.3f}")

    return optimized_chatbot


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    # è©•ä¾¡ç”¨LLMã®è¨­å®š
    eval_lm = dspy.LM(
        model="openai/gpt-4.1-mini",
        temperature=0.0,
        max_tokens=4096
    )

    # ãƒãƒ£ãƒƒãƒˆæ¨è«–ç”¨LLMã®è¨­å®š
    chat_lm = dspy.LM(
        model="openai/gpt-4.1-nano",
        temperature=0.0,
        max_tokens=1000
    )
        
    # æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿ï¼ˆãšã‚“ã ã‚‚ã‚“ã‚¹ã‚¿ã‚¤ãƒ«ã®è³ªå•å¿œç­”ãƒ‡ãƒ¼ã‚¿ï¼‰
    dataset = load_dataset("takaaki-inada/databricks-dolly-15k-ja-zundamon")

    # ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä»¶æ•°
    train_num = 30
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰DSPyå½¢å¼ã®Exampleã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
    # - query: è³ªå•æ–‡
    # - history: ä¼šè©±å±¥æ­´ï¼ˆä»Šå›ã¯ç©ºãƒªã‚¹ãƒˆï¼‰
    # - response: æœŸå¾…ã•ã‚Œã‚‹å¿œç­”ï¼ˆå­¦ç¿’ç”¨ï¼‰
    trainset = [
        dspy.Example(
            query=item['instruction'],
            history=[],
            response=item['output']
        ).with_inputs("query", "history")  # å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒ‡å®š
        for item in list(dataset['train'])[:train_num]  # æœ€åˆã®30ä»¶ã‚’ä½¿ç”¨
    ]
    
    # MIPROv2ã‚’ä½¿ç”¨ã—ã¦ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’æœ€é©åŒ–
    optimized_bot = optimize_with_miprov2(trainset, eval_lm, chat_lm)
    
    # æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    optimized_bot.save(OPTIMIAZED_MODEL_PATH)
    print(f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {OPTIMIAZED_MODEL_PATH}")

    # ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ†ã‚¹ãƒˆ
    test_bot = EdamameFairyBot()
    test_bot.load(OPTIMIAZED_MODEL_PATH)

    # ãƒ†ã‚¹ãƒˆç”¨ã®LMè¨­å®šï¼ˆæ¨è«–ç”¨ï¼‰
    dspy.configure(lm=chat_lm)
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¯ã‚¨ãƒªï¼ˆæ§˜ã€…ãªã‚¿ã‚¤ãƒ—ã®è³ªå•ï¼‰
    test_queries = [
        "ã“ã‚“ã«ã¡ã¯ï¼",
        "æè±†ã£ã¦ç¾å‘³ã—ã„ã‚ˆã­",
        "DSPyã«ã¤ã„ã¦æ•™ãˆã¦"
    ]
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã¨çµæœè¡¨ç¤º
    print("\nğŸ§ª ãƒ†ã‚¹ãƒˆçµæœ:")
    for query in test_queries:
        # æœ€é©åŒ–ã•ã‚ŒãŸãƒœãƒƒãƒˆã§å¿œç­”ã‚’ç”Ÿæˆ
        result = test_bot(query=query, history=[])
        print(f"Q: {query}")
        print(f"A: {result.response}\n")


if __name__ == "__main__":
    main()