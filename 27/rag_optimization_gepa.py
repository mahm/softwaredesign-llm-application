"""
RAGæœ€é©åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (GEPAç‰ˆ)
"""

import os
import random
import argparse
import dspy # type: ignore
from datetime import datetime

from config import configure_lm, configure_embedder, SMART_MODEL, FAST_MODEL, RETRIEVAL_K
from rag_module import RAGQA
from dataset_loader import load_jqara_dataset
from evaluator import evaluation, rag_comprehensive_metric
from embeddings_cache import get_cached_embeddings_retriever

# æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å…ˆï¼ˆæœ€æ–°ç‰ˆã¸ã®ãƒªãƒ³ã‚¯ï¼‰
GEPA_OPTIMIZED_MODEL_LATEST = "artifact/rag_gepa_optimized_latest.json"


def gepa_metric_with_feedback(gold, pred, trace=None, pred_name=None, pred_trace=None):
    """GEPAç”¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹é–¢æ•°ï¼ˆã‚¹ã‚³ã‚¢ + ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼‰

    Args:
        gold: æ­£è§£ãƒ‡ãƒ¼ã‚¿
        pred: äºˆæ¸¬çµæœ
        trace: ãƒ—ãƒ­ã‚°ãƒ©ãƒ å…¨ä½“ã®å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        pred_name: æœ€é©åŒ–ä¸­ã®ç‰¹å®šã®predictorã®åå‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        pred_trace: ç‰¹å®šã®predictorã®å®Ÿè¡Œãƒˆãƒ¬ãƒ¼ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

    Returns:
        dspy.Prediction: ScoreWithFeedbackå‹ï¼ˆscoreã¨feedbackãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒã¤ï¼‰
    """
    # åŸºæœ¬ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆæ—¢å­˜ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä½¿ç”¨ï¼‰
    score = rag_comprehensive_metric(gold, pred, trace)

    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆ
    feedback_parts = []

    # å›ç­”ã®è©•ä¾¡
    if pred.answer.strip() == gold.answer.strip():
        feedback_parts.append("âœ“ å®Œå…¨ä¸€è‡´")
    else:
        # éƒ¨åˆ†ä¸€è‡´ãƒã‚§ãƒƒã‚¯
        pred_lower = pred.answer.strip().lower()
        gold_lower = gold.answer.strip().lower()
        if gold_lower in pred_lower or pred_lower in gold_lower:
            feedback_parts.append(f"â–³ éƒ¨åˆ†ä¸€è‡´: æœŸå¾…={gold.answer}, å®Ÿéš›={pred.answer}")
        else:
            feedback_parts.append(f"âœ— ä¸æ­£è§£: æœŸå¾…={gold.answer}, å®Ÿéš›={pred.answer}")

    # æ¤œç´¢ç²¾åº¦ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
    retrieved = set(pred.retrieved_passages) if hasattr(pred, 'retrieved_passages') else set()
    positives = set(gold.positives) if hasattr(gold, 'positives') and gold.positives else set()

    if positives:
        overlap = len(retrieved & positives)
        max_retrievable = min(len(positives), RETRIEVAL_K)
        recall = overlap / max_retrievable if max_retrievable > 0 else 0

        if recall >= 0.8:
            feedback_parts.append(f"âœ“ æ¤œç´¢è‰¯å¥½: {overlap}/{max_retrievable}å€‹ã®æ­£è§£æ–‡æ›¸")
        elif recall >= 0.5:
            feedback_parts.append(f"â–³ æ¤œç´¢æ”¹å–„ä½™åœ°: {overlap}/{max_retrievable}å€‹ã®æ­£è§£æ–‡æ›¸")
        else:
            feedback_parts.append(f"âœ— æ¤œç´¢ä¸è‰¯: {overlap}/{max_retrievable}å€‹ã®æ­£è§£æ–‡æ›¸")

        # ã‚¯ã‚¨ãƒªæ”¹å–„ã®ææ¡ˆ
        if recall < 0.5 and hasattr(pred, 'rewritten_query'):
            feedback_parts.append(f"ã‚¯ã‚¨ãƒªæ”¹å–„ã‚’æ¤œè¨: '{pred.rewritten_query}'")

    # predictorå›ºæœ‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆã‚‚ã—æŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ï¼‰
    if pred_name:
        feedback_parts.append(f"[{pred_name}]")

    # GEPAã¯ScoreWithFeedbackå‹ï¼ˆdspy.Predictionï¼‰ã‚’æœŸå¾…
    return dspy.Prediction(
        score=score,
        feedback=" | ".join(feedback_parts)
    )


def main(seed=42):
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°

    Args:
        seed: ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 42ï¼‰
    """

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ï¼ˆdevã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ï¼‰
    examples, corpus_texts = load_jqara_dataset(num_questions=50, dataset_split='dev', random_seed=seed)

    # Train/Valåˆ†å‰²ï¼ˆ50:50ï¼‰
    random.seed(seed)  # å¼•æ•°ã®ã‚·ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
    random.shuffle(examples)
    split = int(len(examples) * 0.5)
    trainset = examples[:split]
    valset = examples[split:]
    print(f"âœ‚ï¸ ãƒ‡ãƒ¼ã‚¿åˆ†å‰² (dev): train={len(trainset)}, val={len(valset)}")

    # testã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ï¼ˆ30å•ï¼‰
    testset, test_corpus_texts = load_jqara_dataset(num_questions=30, dataset_split='test', random_seed=seed)

    # LMè¨­å®š
    print("\nğŸ”§ ãƒ¢ãƒ‡ãƒ«è¨­å®šä¸­...")
    # æœ€é©åŒ–ç”¨ï¼ˆé«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ï¼‰
    smart_lm = configure_lm(SMART_MODEL, temperature=0.0, max_tokens=4096)
    # æ¨è«–ç”¨ï¼ˆé«˜é€Ÿãƒ¢ãƒ‡ãƒ«ï¼‰
    fast_lm = configure_lm(FAST_MODEL, temperature=0.0, max_tokens=4096)

    # GEPAã®ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ç”¨LMï¼ˆé«˜æ¸©åº¦è¨­å®šï¼‰
    reflection_lm = configure_lm(SMART_MODEL, temperature=1.0, max_tokens=8192)

    # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«è¨­å®š
    embedder = configure_embedder()

    # Retrieverã®æ§‹ç¯‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãï¼‰
    print("ğŸ” æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ä¸­...")
    retriever = get_cached_embeddings_retriever(
        embedder=embedder,
        corpus_texts=corpus_texts,
        k=RETRIEVAL_K  # æ¤œç´¢çµæœæ•°
    )

    # DSPyã§ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’è¨­å®š
    dspy.configure(lm=fast_lm, rm=retriever)

    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è©•ä¾¡ï¼ˆtestã‚»ãƒƒãƒˆã§è©•ä¾¡ï¼‰
    print("\nğŸ“Š ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è©•ä¾¡ä¸­...")
    baseline = RAGQA()
    base_results = evaluation(baseline, examples=testset, corpus_texts=test_corpus_texts, display_table=0)

    # GEPAæœ€é©åŒ–
    print("\nğŸš€ GEPAæœ€é©åŒ–ã‚’é–‹å§‹...")
    print("  â€»GEPAã¯ãƒªãƒ•ãƒ¬ã‚¯ãƒ†ã‚£ãƒ–ãªé€²åŒ–çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æœ€é©åŒ–ã—ã¾ã™")

    # æœ€é©åŒ–å¯¾è±¡ã®RAGãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
    rag = RAGQA()

    # GEPAã®è¨­å®š
    optimizer = dspy.GEPA(
        metric=gepa_metric_with_feedback,  # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä»˜ããƒ¡ãƒˆãƒªã‚¯ã‚¹
        auto="medium",  # æœ€é©åŒ–ã®å¼·åº¦
        num_threads=4,  # ä¸¦åˆ—ã‚¹ãƒ¬ãƒƒãƒ‰æ•°
        reflection_minibatch_size=3,  # ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ™‚ã®ãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚º
        reflection_lm=reflection_lm,  # ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ç”¨ã®LMï¼ˆå¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«æ¨å¥¨ï¼‰
        candidate_selection_strategy="pareto",  # ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©åŒ–æˆ¦ç•¥
        track_stats=True,  # çµ±è¨ˆæƒ…å ±ã®è¿½è·¡
    )

    # æœ€é©åŒ–å®Ÿè¡Œï¼ˆRAGã®æ¨è«–ã¯fast_lmã€ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¯reflection_lmã‚’ä½¿ç”¨ï¼‰
    optimized_rag = optimizer.compile(
        rag,
        trainset=trainset,
        valset=valset,
    )

    # æœ€é©åŒ–å¾Œã®è©•ä¾¡ï¼ˆtestã‚»ãƒƒãƒˆï¼‰
    print("\nğŸ“Š æœ€é©åŒ–å¾Œã®è©•ä¾¡ä¸­...")
    opt_results = evaluation(optimized_rag, examples=testset, corpus_texts=test_corpus_texts, display_table=0)
    print(f"  [Baseline] EM: {base_results.score:.1f}%")
    print(f"  [GEPA Optimized] EM: {opt_results.score:.1f}%")
    print(f"  æ”¹å–„: {opt_results.score - base_results.score:+.1f}%")

    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨ã‚¹ã‚³ã‚¢ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆï¼ˆtestã‚»ãƒƒãƒˆã®ã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    em_score_str = f"em{int(opt_results.score):03d}"
    model_filename = f"rag_gepa_optimized_{timestamp}_{em_score_str}.json"
    model_path = os.path.join("artifact", model_filename)

    # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
    os.makedirs("artifact", exist_ok=True)
    optimized_rag.save(model_path)
    print(f"\nğŸ’¾ æœ€é©åŒ–æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜: {model_path}")

    # æœ€æ–°ç‰ˆã¸ã®ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ä½œæˆ
    if os.path.exists(GEPA_OPTIMIZED_MODEL_LATEST):
        os.remove(GEPA_OPTIMIZED_MODEL_LATEST)
    os.symlink(model_filename, GEPA_OPTIMIZED_MODEL_LATEST)

    print(f"  â†’ æœ€æ–°ãƒªãƒ³ã‚¯: {GEPA_OPTIMIZED_MODEL_LATEST}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='RAGã®æœ€é©åŒ– (GEPAç‰ˆ)')
    parser.add_argument('--seed', type=int, default=42,
                       help='ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 42ï¼‰')
    args = parser.parse_args()

    print(f"ğŸŒ± ã‚·ãƒ¼ãƒ‰å€¤: {args.seed}")
    print("ğŸ§¬ æœ€é©åŒ–æ‰‹æ³•: GEPA (Gradient-Estimation with Prompt Augmentation)")
    main(seed=args.seed)